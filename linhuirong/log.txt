
【量化投资利器Python】基本类库-pandas入门-数据结构¶
量化投资中广泛使用的数据结构有Series和DataFrame，便是Pandas中的。下面将进行详细介绍
Series：一维数组，与Numpy中的一维array类似。二者与Python基本的数据结构List也很相近，其区别是：List中的元素可以是不同的数据类型，而Array和Series中则只允许存储相同的数据类型，这样可以更有效的使用内存，提高运算效率。
Time- Series：以时间为索引的Series。
DataFrame：二维的表格型数据结构。很多功能与R中的data.frame类似。可以将DataFrame理解为Series的容器。以下的内容主要以DataFrame为主。
Panel ：三维的数组，可以理解为DataFrame的容器。
Pandas官网，更多功能请参考http://pandas-docs.github.io/pandas-docs-travis/index.html
In [1]:
# 首先导入库
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
一、数据结构介绍
1、Series
由一组数据（各种Numpy数据类型），以及一组与之相关的标签数据（即索引）组成。仅由一组数据即可产生最简单的Series，可以通过传递一个list对象来创建一个Series，pandas会默认创建整型索引,更多series内容请参考官网 http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html
In [2]:
s = pd.Series([1,3,5,np.nan,6,8])
s
Out[2]:
0     1
1     3
2     5
3   NaN
4     6
5     8
dtype: float64
也可以通过字典来创建Series
In [3]:
sdata = {'a':1,'b':2,'c':3}
s1 = pd.Series(sdata)
s1
Out[3]:
a    1
b    2
c    3
dtype: int64
索引相匹配的会被找出来并放到相应的位置上，但‘d’所对于的值找不到，所有结果为NaN(即非数字，not a number),可以使用isnull和notnull来检测缺失数据
In [4]:
s11 = pd.Series(sdata,index=['a','b','c','d'])
s11
Out[4]:
a     1
b     2
c     3
d   NaN
dtype: float64
In [5]:
pd.isnull(s11)#或是s11.isnull()
Out[5]:
a    False
b    False
c    False
d     True
dtype: bool
In [6]:
s11.notnull()#或pd.notnull(s11)
Out[6]:
a     True
b     True
c     True
d    False
dtype: bool
Series最重要的一个功能是：可以在算术运算中自动对齐不同索引的数据
In [7]:
s1+s11
Out[7]:
a     2
b     4
c     6
d   NaN
dtype: float64
Series对象本身及其索引都有一个name属性
In [8]:
s1.name = 'population'
s1.index.name = 'state'
s1
Out[8]:
state
a    1
b    2
c    3
Name: population, dtype: int64
Series的索引可以通过赋值的方式就地修改
In [9]:
s1.index = ['Join','Quant','JQ']
s1
Out[9]:
Join     1
Quant    2
JQ       3
Name: population, dtype: int64
通过values和index属性获取其数组表示形式和索引对象
In [10]:
s.values
Out[10]:
array([  1.,   3.,   5.,  nan,   6.,   8.])
In [11]:
s.index
Out[11]:
Int64Index([0, 1, 2, 3, 4, 5], dtype='int64')
带有一个可以通过对各个数据点进行标记的索引
In [12]:
s2 = pd.Series([1,3,-6,8],index=['a','d','e','c'])
s2
Out[12]:
a    1
d    3
e   -6
c    8
dtype: int64
可以通过索引的方式选取Series中的单个或一组值
In [13]:
s2['a']
Out[13]:
1
In [14]:
s2[['a','c']]
Out[14]:
a    1
c    8
dtype: int64
Numpy数组运算（如根据布尔型数组进行过滤、标量乘法、应用数学函数等）都会保留索引和值之间的链接
In [15]:
s2[s2>0]
Out[15]:
a    1
d    3
c    8
dtype: int64
In [16]:
s2*2
Out[16]:
a     2
d     6
e   -12
c    16
dtype: int64
In [17]:
np.exp(s2)
Out[17]:
a       2.718282
d      20.085537
e       0.002479
c    2980.957987
dtype: float64
还可以将Series看成是一个定长的有序字典，因为它是索引值到数据值得一个映射。它可以用在许多原本需要字典参数的函数中：
In [18]:
'a' in s2
Out[18]:
True
In [26]:
s2
Out[26]:
a    1
d    3
e   -6
c    8
dtype: int64
In [25]:
s2.add(1)
Out[25]:
a    2
d    4
e   -5
c    9
dtype: int64
2、DataFrame
DataFrame是一个表格型的数据结构，它含有一组有序的列，每一列的数据结构都是相同的，而不同的列之间则可以是不同的数据结构（数值、字符、布尔值等）。或者以数据库进行类比，DataFrame中的每一行是一个记录，名称为Index的一个元素，而每一列则为一个字段，是这个记录的一个属性。DataFrame既有行索引也有列索引，可以被看做由Series组成的字典（共用同一个索引）。
更多内容请参考：http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html
创建DataFrame有多种方式：
1.以字典的字典或Series的字典的结构构建DataFrame，这时候的最外面字典对应的是DataFrame的列，内嵌的字典及Series则是其中每个值。
In [19]:
d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}
df = pd.DataFrame(d)
df
Out[19]:
one	two
a	1	1
b	2	2
c	3	3
d	NaN	4
可以看到d是一个字典，其中one的值为Series有3个值，而two为Series有4个值。由d构建的为一个4行2列的DataFrame。其中one只有3个值，因此d行one列为NaN。
In [20]:
df2 = pd.DataFrame({ 'A' : 1.,
   ....:            'B' : pd.Timestamp('20160101'),
   ....:            'C' : pd.Series(1,index=list(range(4)),dtype='float32'),
   ....:            'D' : np.array([3] * 4,dtype='int32'),
   ....:            'E' : pd.Categorical(["test","train","test","train"]),
   ....:            'F' : 'foo' })
df2
Out[20]:
A	B	C	D	E	F
0	1	2016-01-01	1	3	test	foo
1	1	2016-01-01	1	3	train	foo
2	1	2016-01-01	1	3	test	foo
3	1	2016-01-01	1	3	train	foo
2.从列表的字典构建DataFrame，其中嵌套的每个列表（List）代表的是一个列，字典的名字则是列标签。这里要注意的是每个列表中的元素数量应该相同。通过传递一个numpy array，时间索引以及列标签来创建一个
In [21]:
dates = pd.date_range('20160101',periods=6)
df3 = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list('ABCD'))
df3
Out[21]:
A	B	C	D
2016-01-01	-1.113506	0.823869	1.334366	-1.228612
2016-01-02	-0.452546	-0.380858	0.471212	-0.553034
2016-01-03	-0.958349	0.528585	0.742589	0.057017
2016-01-04	1.209820	1.099186	-0.841838	1.445381
2016-01-05	-0.425561	-1.152818	-0.172490	-0.516070
2016-01-06	-0.107563	-0.094983	0.102025	-0.524834
3.从字典的列表构建DataFrame，其中每个字典代表的是每条记录（DataFrame中的一行），字典中每个值对应的是这条记录的相关属性。
In [22]:
d = [{'one' : 1,'two':1},{'one' : 2,'two' : 2},{'one' : 3,'two' : 3},{'two' : 4}]
df = pd.DataFrame(d,index=['a','b','c','d'],columns=['one','two'])
df.index.name='index'
df
Out[22]:
one	two
index		
a	1	1
b	2	2
c	3	3
d	NaN	4
以上的语句与以Series的字典形式创建的DataFrame相同，只是思路略有不同，一个是以列为单位构建，将所有记录的不同属性转化为多个Series，行标签冗余，另一个是以行为单位构建，将每条记录转化为一个字典，列标签冗余。使用这种方式，如果不通过columns指定列的顺序，那么列的顺序会是随机的。
为不存在的列赋值会创建出一个新列。关键字del用于删除列
In [25]:
df['quant'] = 6
df
Out[25]:
one	two	quant
index			
a	1	1	6
b	2	2	6
c	3	3	6
d	NaN	4	6
In [26]:
del df['quant']
df
Out[26]:
one	two
index		
a	1	1
b	2	2
c	3	3
d	NaN	4
查看不同列的数据类型：
In [27]:
df.dtypes
Out[27]:
one    float64
two      int64
dtype: object
DataFrame转换为其他类型
orient的参数为‘dict’、‘list’、‘series’和‘records’。
In [28]:
df.to_dict(orient='dict')
Out[28]:
{'one': {'a': 1.0, 'b': 2.0, 'c': 3.0, 'd': nan},
 'two': {'a': 1, 'b': 2, 'c': 3, 'd': 4}}
可以使用Tab自动补全功能会自动识别所有的属性以及自定义的列，下图中是所有能够被自动识别的属性的一个子集：
In [ ]:
df2.<TAB>
df2.A df2.boxplot df2.abs df2.C df2.add df2.clip df2.add_prefix df2.clip_lower df2.add_suffix df2.clip_upper df2.align df2.columns df2.all df2.combine df2.any df2.combineAdd df2.append df2.combine_first df2.apply df2.combineMult df2.applymap df2.compound df2.as_blocks df2.consolidate df2.asfreq df2.convert_objects df2.as_matrix df2.copy df2.astype df2.corr df2.at df2.corrwith df2.at_time df2.count df2.axes df2.cov df2.B df2.cummax df2.between_time df2.cummin df2.bfill df2.cumprod df2.blocks df2.cumsum df2.bool df2.D
获取DataFrame的列为一个Series有两种方式
In [29]:
df['one']
Out[29]:
index
a     1
b     2
c     3
d   NaN
Name: one, dtype: float64
In [30]:
df.one
Out[30]:
index
a     1
b     2
c     3
d   NaN
Name: one, dtype: float64
返回的Series拥有原DataFrame相同的所有，且其name属性也被相应设置好了。行也可以通过位置或名称方式获取
3、Panel
平台get_price，如果是多支, 则返回pandas.Panel对象。更多内容请参考http://pandas.pydata.org/pandas-docs/stable/api.html#panel
In [27]:
pdata = get_price(['000300.XSHG', '000001.XSHE'])
pdata
Out[27]:
<class 'pandas.core.panel.Panel'>
Dimensions: 6 (items) x 244 (major_axis) x 2 (minor_axis)
Items axis: close to volume
Major_axis axis: 2015-01-05 00:00:00 to 2015-12-31 00:00:00
Minor_axis axis: 000001.XSHE to 000300.XSHG
In [28]:
stacked = pdata.ix[:,'2015-07-04 00:00:00':,:].to_frame()
stacked.head()
Out[28]:
close	high	low	money	open	volume
major	minor						
2015-07-06	000001.XSHE	13.88	14.31	13.29	4.660186e+09	14.30	338152672
000300.XSHG	3998.54	4218.27	3832.47	7.795580e+11	4218.27	64809453000
2015-07-07	000001.XSHE	14.65	14.65	13.21	6.808004e+09	13.66	480831200
000300.XSHG	3928.00	3960.64	3743.62	7.959626e+11	3877.85	67938500700
2015-07-08	000001.XSHE	13.19	14.00	13.19	6.762103e+09	13.81	499669696
In [35]:
pdata.ix[:,:,0].head()
Out[35]:
close	high	low	money	open	volume
2015-01-05	13.23	13.45	12.89	4565387776	13.21	346261028
2015-01-06	13.04	13.54	12.85	3453446144	13.09	262249248
2015-01-07	12.79	13.08	12.64	2634796288	12.85	205802690
2015-01-08	12.36	12.86	12.31	2128003456	12.80	170406364
2015-01-09	12.46	13.11	12.15	3835378176	12.31	303658498
In [31]:
pdata.minor_xs('000001.XSHE').head()
Out[31]:
close	high	low	money	open	volume
2015-01-05	13.23	13.45	12.89	4565387776	13.21	346261028
2015-01-06	13.04	13.54	12.85	3453446144	13.09	262249248
2015-01-07	12.79	13.08	12.64	2634796288	12.85	205802690
2015-01-08	12.36	12.86	12.31	2128003456	12.80	170406364
2015-01-09	12.46	13.11	12.15	3835378176	12.31	303658498
In [32]:
pdata.major_xs('2015-01-05')
Out[32]:
close	high	low	money	open	volume
000001.XSHE	13.23	13.45	12.89	4.565388e+09	13.21	346261028
000300.XSHG	3641.54	3669.04	3551.51	5.198498e+11	3566.09	45119809800
In [33]:
stacked.to_panel()
Out[33]:
<class 'pandas.core.panel.Panel'>
Dimensions: 6 (items) x 122 (major_axis) x 2 (minor_axis)
Items axis: close to volume
Major_axis axis: 2015-07-06 00:00:00 to 2015-12-31 00:00:00
Minor_axis axis: 000001.XSHE to 000300.XSHG
二、查看数据
1、查看数据的前几条&后几条数据
In [34]:
dates = pd.date_range('20150101',periods=30)
df = pd.DataFrame(np.random.randn(30,4),index=dates,columns=list('ABCD'))
df.head()
Out[34]:
A	B	C	D
2015-01-01	-1.288885	0.100184	-1.123152	1.481061
2015-01-02	0.715922	1.054161	0.165483	0.954136
2015-01-03	1.007141	-1.843268	-1.658547	0.239509
2015-01-04	-0.117214	-0.427071	0.717396	2.705250
2015-01-05	0.344063	-0.785480	-2.934375	1.046888
In [35]:
df.tail(3)
Out[35]:
A	B	C	D
2015-01-28	1.729071	2.424110	-0.276512	0.250709
2015-01-29	-0.267186	-0.137241	0.737485	-0.003254
2015-01-30	2.066402	-2.757171	-1.108371	2.139467
2、 显示索引、列和底层的numpy数据：
In [ ]:
df.index
In [37]:
df.columns
Out[37]:
Index([u'A', u'B', u'C', u'D'], dtype='object')
In [ ]:
df.values
3、 describe()函数对于数据的快速统计汇总：
In [39]:
df.describe()
Out[39]:
A	B	C	D
count	30.000000	30.000000	30.000000	30.000000
mean	0.425665	-0.182597	-0.398589	0.183658
std	1.190162	1.160109	0.997315	1.151604
min	-2.059408	-2.757171	-2.934375	-1.770773
25%	-0.272036	-1.048372	-1.083784	-0.561252
50%	0.587310	0.046034	-0.375715	0.072713
75%	1.437348	0.487290	0.281880	0.896345
max	2.331571	2.424110	1.571488	2.705250
4、 对数据的转置：
In [40]:
df.T
Out[40]:
2015-01-01 00:00:00	2015-01-02 00:00:00	2015-01-03 00:00:00	2015-01-04 00:00:00	2015-01-05 00:00:00	2015-01-06 00:00:00	2015-01-07 00:00:00	2015-01-08 00:00:00	2015-01-09 00:00:00	2015-01-10 00:00:00	...	2015-01-21 00:00:00	2015-01-22 00:00:00	2015-01-23 00:00:00	2015-01-24 00:00:00	2015-01-25 00:00:00	2015-01-26 00:00:00	2015-01-27 00:00:00	2015-01-28 00:00:00	2015-01-29 00:00:00	2015-01-30 00:00:00
A	-1.288885	0.715922	1.007141	-0.117214	0.344063	1.624201	-2.059408	-0.962735	0.294492	1.693810	...	1.282831	-0.328599	-0.177310	-1.810267	-0.273653	-0.171810	1.560582	1.729071	-0.267186	2.066402
B	0.100184	1.054161	-1.843268	-0.427071	-0.785480	0.564591	-1.136002	0.518131	0.394767	-1.733726	...	-0.303924	-1.198145	1.438052	0.174793	0.327991	0.276747	-2.035762	2.424110	-0.137241	-2.757171
C	-1.123152	0.165483	-1.658547	0.717396	-2.934375	-0.414299	-0.106407	-0.778278	-1.749258	0.695285	...	0.209735	0.305928	-0.393329	-1.010024	1.571488	0.607875	0.997825	-0.276512	0.737485	-1.108371
D	1.481061	0.954136	0.239509	2.705250	1.046888	0.523397	0.148679	-0.221758	-1.441750	-0.784861	...	-0.707405	0.426369	-0.414233	-0.218488	-1.592056	0.832816	0.779378	0.250709	-0.003254	2.139467
4 rows × 30 columns
5、 按轴进行排序
In [41]:
df.head(5).sort_index(axis=1, ascending=False)
Out[41]:
D	C	B	A
2015-01-01	1.481061	-1.123152	0.100184	-1.288885
2015-01-02	0.954136	0.165483	1.054161	0.715922
2015-01-03	0.239509	-1.658547	-1.843268	1.007141
2015-01-04	2.705250	0.717396	-0.427071	-0.117214
2015-01-05	1.046888	-2.934375	-0.785480	0.344063
6、 按值进行排序
In [42]:
df.head().sort(columns='B')
Out[42]:
A	B	C	D
2015-01-03	1.007141	-1.843268	-1.658547	0.239509
2015-01-05	0.344063	-0.785480	-2.934375	1.046888
2015-01-04	-0.117214	-0.427071	0.717396	2.705250
2015-01-01	-1.288885	0.100184	-1.123152	1.481061
2015-01-02	0.715922	1.054161	0.165483	0.954136
7、描述
In [43]:
df.shape
Out[43]:
(30, 4)
In [44]:
df.size
Out[44]:
120
三、选择
1. 通过下标选取数据:
df['one']，df.one
以上两个语句是等效的，都是返回df名称为one列的数据，返回的为一个Series。
df[0:3]，df[0]
下标索引选取的是DataFrame的记录，与List相同DataFrame的下标也是从0开始，区间索引的话，为一个左闭右开的区间，即[0：3]选取的为0-2三条记录。与此等价，还可以用起始的索引名称和结束索引名称选取数据,如：df['a':'b']
有一点需要注意的是使用起始索引名称和结束索引名称时，也会包含结束索引的数据。以上两种方式返回的都是DataFrame。
2. 使用标签选取数据：
df.loc[行标签,列标签]
df.loc['a':'b']#选取ab两行数据
df.loc[:,'one']#选取one列的数据
df.loc的第一个参数是行标签，第二个参数为列标签（可选参数，默认为所有列标签），两个参数既可以是列表也可以是单个字符，如果两个参数都为列表则返回的是DataFrame，否则，则为Series。
3. 使用位置选取数据：
df.iloc[行位置,列位置]
df.iloc[1,1]#选取第二行，第二列的值，返回的为单个值
df.iloc[0,2],:]#选取第一行及第三行的数据
df.iloc[0:2,:]#选取第一行到第三行（不包含）的数据
df.iloc[:,1]#选取所有记录的第一列的值，返回的为一个Series
df.iloc[1,:]#选取第一行数据，返回的为一个Series
PS：loc为location的缩写，iloc则为integer & location的缩写
4. 更广义的切片方式是使用.ix，它自动根据给到的索引类型判断是使用位置还是标签进行切片
df.ix[1,1]
df.ix['a':'b']
通过逻辑指针进行数据切片：
df[逻辑条件]
df[df.one >= 2]#单个逻辑条件
df[(df.one >=1 ) & (df.one < 3) ]#多个逻辑条件组合
1、获取
1）选择一个单独的列，这将会返回一个Series，等同于df.A：
In [45]:
dates = pd.date_range('20150101',periods=5)
df = pd.DataFrame(np.random.randn(5,4),index=dates,columns=list('ABCD'))
df['A']
Out[45]:
2015-01-01   -0.350716
2015-01-02   -0.463883
2015-01-03   -1.127624
2015-01-04    0.304686
2015-01-05    0.081589
Freq: D, Name: A, dtype: float64
2）通过[ ]进行选择，这将会对行进行切片
In [46]:
df[0:3]
Out[46]:
A	B	C	D
2015-01-01	-0.350716	-0.370551	-1.159448	0.112866
2015-01-02	-0.463883	0.273347	0.217844	0.249154
2015-01-03	-1.127624	0.785656	1.827608	-0.069509
In [47]:
df['20150104':'20150106']
Out[47]:
A	B	C	D
2015-01-04	0.304686	0.897422	0.577268	-0.310842
2015-01-05	0.081589	0.845999	0.358836	-0.274310
2、通过标签选择
1）使用标签来获取一个交叉的区域
In [48]:
df.loc[dates[0]]
Out[48]:
A   -0.350716
B   -0.370551
C   -1.159448
D    0.112866
Name: 2015-01-01 00:00:00, dtype: float64
2） 通过标签来在多个轴上进行选择
In [49]:
df.loc[:,['A','B']]
Out[49]:
A	B
2015-01-01	-0.350716	-0.370551
2015-01-02	-0.463883	0.273347
2015-01-03	-1.127624	0.785656
2015-01-04	0.304686	0.897422
2015-01-05	0.081589	0.845999
3） 标签切片
In [50]:
df.loc['20150101':'20150103','A':'B']
Out[50]:
A	B
2015-01-01	-0.350716	-0.370551
2015-01-02	-0.463883	0.273347
2015-01-03	-1.127624	0.785656
4） 对于返回的对象进行维度缩减
In [51]:
df.loc['20150101','A':'B']
Out[51]:
A   -0.350716
B   -0.370551
Name: 2015-01-01 00:00:00, dtype: float64
5） 获取一个标量
In [52]:
df.loc[dates[0],'A']
Out[52]:
-0.3507158545641505
6） 快速访问一个标量（与上一个方法等价）
In [53]:
df.at[dates[0],'A']
Out[53]:
-0.3507158545641505
3、通过位置选择
1） 通过传递数值进行位置选择（选择的是行）
In [54]:
df.iloc[3]
Out[54]:
A    0.304686
B    0.897422
C    0.577268
D   -0.310842
Name: 2015-01-04 00:00:00, dtype: float64
2） 通过数值进行切片
In [55]:
df.iloc[3:5,0:2]
Out[55]:
A	B
2015-01-04	0.304686	0.897422
2015-01-05	0.081589	0.845999
3） 通过指定一个位置的列表
In [56]:
df.iloc[[1,2,4],[0,2]]
Out[56]:
A	C
2015-01-02	-0.463883	0.217844
2015-01-03	-1.127624	1.827608
2015-01-05	0.081589	0.358836
4）对行进行切片
In [57]:
df.iloc[1:3,:]
Out[57]:
A	B	C	D
2015-01-02	-0.463883	0.273347	0.217844	0.249154
2015-01-03	-1.127624	0.785656	1.827608	-0.069509
5）对列进行切片
In [58]:
df.iloc[:,1:3]
Out[58]:
B	C
2015-01-01	-0.370551	-1.159448
2015-01-02	0.273347	0.217844
2015-01-03	0.785656	1.827608
2015-01-04	0.897422	0.577268
2015-01-05	0.845999	0.358836
6）获取特定的值
In [59]:
df.iloc[1,1]
Out[59]:
0.27334674183560975
In [60]:
df.iat[1,1]
Out[60]:
0.27334674183560975
4、布尔索引
1）使用一个单独列的值来选择数据：
In [61]:
df[df.A>0]
Out[61]:
A	B	C	D
2015-01-04	0.304686	0.897422	0.577268	-0.310842
2015-01-05	0.081589	0.845999	0.358836	-0.274310
2） 使用where操作来选择数据：
In [62]:
df[df>0]
Out[62]:
A	B	C	D
2015-01-01	NaN	NaN	NaN	0.112866
2015-01-02	NaN	0.273347	0.217844	0.249154
2015-01-03	NaN	0.785656	1.827608	NaN
2015-01-04	0.304686	0.897422	0.577268	NaN
2015-01-05	0.081589	0.845999	0.358836	NaN
3）使用isin()方法来过滤：
In [68]:
df2 = pd.DataFrame(np.random.randn(5,4),index=dates,columns=list('ABCD'))
df2['E']=['one', 'one','two','three','four']
df2
Out[68]:
A	B	C	D	E
2015-01-01	-1.452233	0.856054	0.415182	2.017830	one
2015-01-02	-0.993872	0.289162	-0.272178	-0.828804	one
2015-01-03	-1.372667	-0.383118	0.169221	1.049816	two
2015-01-04	1.696327	-0.629723	-0.445219	-0.073686	three
2015-01-05	1.700180	0.228395	-1.447462	-2.134411	four
In [69]:
df2[df2['E'].isin(['two','four'])]
Out[69]:
A	B	C	D	E
2015-01-03	-1.372667	-0.383118	0.169221	1.049816	two
2015-01-05	1.700180	0.228395	-1.447462	-2.134411	four
5、设置
1） 设置一个新的列：
In [70]:
s1 = pd.Series([1,2,3,4,5,6],index=pd.date_range('20150101',periods=6))
s1
Out[70]:
2015-01-01    1
2015-01-02    2
2015-01-03    3
2015-01-04    4
2015-01-05    5
2015-01-06    6
Freq: D, dtype: int64
In [71]:
dates = pd.date_range('20150101',periods=5)
df = pd.DataFrame(np.random.randn(5,4),index=dates,columns=list('ABCD'))
df['F'] = s1
df
Out[71]:
A	B	C	D	F
2015-01-01	-1.291203	2.457971	0.605757	0.519269	1
2015-01-02	0.247173	-0.348339	0.550066	-0.906294	2
2015-01-03	0.436003	-1.706036	0.301697	0.992056	3
2015-01-04	-1.251305	-0.133439	1.376389	-0.861442	4
2015-01-05	-0.602147	1.947313	2.381003	-0.449390	5
2）通过标签设置新的值：
In [72]:
df.at[dates[0],'A'] = 0
3） 通过位置设置新的值：
In [73]:
df.iat[0,1] = 0
4）通过一个numpy数组设置一组新值：
In [74]:
df.loc[:,'D'] = np.array([5] * len(df))
df
Out[74]:
A	B	C	D	F
2015-01-01	0.000000	0.000000	0.605757	5	1
2015-01-02	0.247173	-0.348339	0.550066	5	2
2015-01-03	0.436003	-1.706036	0.301697	5	3
2015-01-04	-1.251305	-0.133439	1.376389	5	4
2015-01-05	-0.602147	1.947313	2.381003	5	5
5）通过where操作来设置新的值：
In [75]:
df2 = df.copy()
df2[df2 > 0] = -df2
df2
Out[75]:
A	B	C	D	F
2015-01-01	0.000000	0.000000	-0.605757	-5	-1
2015-01-02	-0.247173	-0.348339	-0.550066	-5	-2
2015-01-03	-0.436003	-1.706036	-0.301697	-5	-3
2015-01-04	-1.251305	-0.133439	-1.376389	-5	-4
2015-01-05	-0.602147	-1.947313	-2.381003	-5	-5
